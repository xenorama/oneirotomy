<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<?xml-stylesheet href="./_c74_ref.xsl" type="text/xsl"?>

<c74object name="the.jit.thalamus" module="jitter" category="Jitter System">

	<digest>
		Manage offline rendering of realtime audiovisual content
		</digest>

	<description>
		Written by Tim Heinze © 2020, www.xenorama.com.
		<br/> Synchronised with a render context hosted by <o>jit.world</o>, performs and manages a linear offline rendering process frame-by-frame. When used in conjunction with other related objects, tight synchronisation of realtime MSP and other timing events can be rendered in high resolution and framerates, respectively.
	</description>

	<discussion>
		This object lies at the core of every offline-rendering process in the <link type="vignette" module="Oneirotomy" name="oneirotomy-00_introduction">Oneirotomy-package</link>. It currently supports render contexts hosted by <o>jit.world</o> only, for reasons explained <link type="vignette" module="Oneirotomy" name="oneirotomy-03_known-limitations">here</link>. All three outlets of <o>jit.world</o> need to be connected to the rightmost inlet of <o>the.jit.thalamus</o> for the latter to receive
		<ul>
			<li>the matrices to render as video</li>
			<li>render bangs, and</li>
			<li>information about the current state of <o>jit.world</o></li>
		</ul>
		Its rightmost outlet connects to the inlet of <o>jit.world</o> to
		<ul>
				<li>send individual render bangs while <o>jit.world</o> is disabled</li>
		</ul>
		Double-clicking the object or sending an <m>open</m> message will pull up a floating window as GUI to monitor and toggle recording/rendering processes.
		<br/>All desired rendering parameters can be set manually in the 'Settings'-tab (or by sending the <m>settings</m> message), all of which can be hard-coded to the object box or sent as Max messages temporarily.
		<br/>
		<br/>
		The <b>thalamus</b> (from Greek θάλαμος, "chamber") is a large mass of gray matter located in the dorsal part of the diencephalon (a division of the forebrain). Nerve fibers project out of the thalamus to the cerebral cortex in all directions, allowing hub-like exchanges of information. It has several functions, such as relaying of sensory signals, including motor signals to the cerebral cortex and the regulation of consciousness, sleep, and alertness.
	</discussion>

	<!--METADATA (REMOVE FOR SIMPLICITY) -->
	<metadatalist>
		<metadata name="author">Tim Heinze</metadata>
		<metadata name="tag">Xenorama</metadata>
		<metadata name="tag">Offline Video Rendering</metadata>
		<metadata name="tag">Jitter System</metadata>
	</metadatalist>

	<!--INLETS (REMOVE FOR SIMPLICITY) -->

	<!--OUTLETS (REMOVE FOR SIMPLICITY) -->

	<!--ARGUMENTS-->
	<objarglist>
		<objarg name="render-context" optional="0" type="symbol" size="1">
			<digest>
				Specify a named render context for all children objects to sync to.
			</digest>
			<description>
				 For convenience, this can be identical to one's world render context name but is to be considered independent. It is necessary to provide a context name for all members of the offline render family to sync and respond to.
			</description>
		</objarg>
	</objarglist>

	<!--ATTRIBUTES (REMOVE FOR SIMPLICITY) -->
	<attributelist>
		<attribute name="container" get="1" set="1" type="list" size="2">
			<arglist>
				<arg name="type" optional="0" type="symbol" />
				<arg name="image format" optional="1" type="symbol" />
			</arglist>
			<digest>
				Specify a the desired video-container
			</digest>
			<description>
				The final video can be either rendered as <m>mov</m> (default) or as <m>img_seq</m>. The latter requires an additional argument to specify the image format, i.e. the attribute or message <m>container img_seq tiff</m> will write successive frames to disk in tiff-format. Any previously saved image files will be overwritten and other ones ignored.
			</description>
		</attribute>
		<attribute name="fps" get="1" set="1" type="float" size="1">
			<digest>
				Specify a desired framerate for the final video.
			</digest>
			<description>
				The desired framerate (default: 30fps) needs to be set prior to beginning a render process and must not be changed throughout.
			</description>
		</attribute>
		<attribute name="dim" get="1" set="1" type="int" size="2">
			<digest>
				Specify a desired dimension (resolution) of the final video.
			</digest>
			<description>
				The resolution of the final video need not be the current resolution but will change accordingly before beginning the render process. The initial dim of the world's render context will be re-established after rendering is complete.
				<br />
				The default render dim is 1280 x 960.
			</description>
		</attribute>
		<attribute name="length" get="1" set="1" type="list" size="1">
			<arglist>
				<arg name="numeric length" optional="0" type="float" />
				<arg name="unit: ms, frames or samples" optional="0" type="symbol" />
			</arglist>
			<digest>
				Specify the length of the final video and all its subrecordings
			</digest>
			<description>
				The word <at>length</at> followed by a floating point or integer value and a symbol specifying a unit, will prepare recording of all children objects for the given length.
				<br/>
				<br />
				Supported units of time are
				<br/> <m>ms</m>
				<br/> <m>frames</m>
				<br/> <m>samples</m>
				<br/>
				<br/>
				Default: <m>length 1000. ms</m>, if the current framerate is set to <m>30.</m> (see also the <at>fps</at> listing), this would yield a length of <m>30 frames</m> and would equal the current <m>samplerate</m> (provided in samples per minute = 1000ms.)
			</description>
		</attribute>
		<attribute name="codec" get="1" set="1" type="symbol" size="1">
			<digest>
				Set movie codec for recording
			</digest>
			<description>
				Set movie codec for recording (default = h264).
			</description>
				</attribute>
				<attribute name="fsaa" get="1" set="1" type="int" size="1">
					<digest>
						Enable full scene anti-aliasing
					</digest>
					<description>
						Enable full scene anti-aliasing during offline rendering (default = 1).
						<br/>
						<br/>
						This setting is temporary to the render process and will not override user settings of <o>jit.world</o>.
					</description>
					<attributelist>
						<attribute name="label" get="1" set="1" type="symbol" size="1" value="FSAA" />
						<attribute name="style" get="1" set="1" type="symbol" size="1" value="onoff" />
					</attributelist>
				</attribute>
			<attribute name="filename" get="1" set="1" type="symbol" size="1">
					<digest>
						Provide a filename for all recorded files to assume
					</digest>
					<description>
						Specify, which filename all generated files should assume when being written to the folder specified by the <at>dir</at> attribute. Objects operating in parallel (see the <m>see also</m> listing at the bottom of th reference page) will require an <at>exportname</at> to format their unique path additionally.
						<br/>
						If omitted, <o>the.jit.thalamus</o> uses a <m>render-context_pfc</m>.
					</description>
			</attribute>
					<attribute name="dir" get="1" set="1" type="symbol" size="1">
						<digest>
							Full path to directory for all export data
						</digest>
						<description>
						The <at>dir</at> attribute specifies a valid path where <at>audiofile</at>, <at>videofile</at>, matrix-data and log-files will be saved to
						</description>
		</attribute>
			<attribute name="autoreveal" get="1" set="1" type="bool" size="1">
				<digest>
					Open the directory upon render completion automatically
				</digest>
				<description>
				Open the directory upon render completion automatically
				</description>
</attribute>
	<attribute name="autoopen" get="1" set="1" type="bool" size="1">
		<digest>
			Open the videofile upon render completion automatically
		</digest>
		<description>
		Open the videofile upon render completion automatically
		</description>
</attribute>
<attribute name="delaytime" get="1" set="1" type="int" size="1">
	<digest>
		Minimum delaytime between render bangs (ms)
	</digest>
	<description>
		Minimum delaytime between subsequent render bangs. The default is <m>10ms</m>. Increase this value to reduce potential errors or lack of precision. This increases the length of the render process proportionally to the length of the videofile.
	</description>
</attribute>
	<attribute name="toggledsp" get="1" set="1" type="bool" size="1">
		<digest>
			Toggle DSP off during offline rendering
		</digest>
		<description>
		Will disable DSP during video rendering process or a potential matrix capturing process and will restore previous DSP state upon render completion.
		<br/>
		The default is 1 (toggle DSP off)
		</description>
</attribute>
<attribute name="toggleworld" get="1" set="1" type="bool" size="1">
	<digest>
		Toggle <o>jit.world</o> off during audio or data recording
	</digest>
	<description>
	Will disable jit.world rendering during audio or data recording and will reactivate it once recording has stopped.
	<br/>
	The default is 1 (toggle video rendering off)
	</description>
</attribute>
<attribute name="toggledsp" get="1" set="1" type="bool" size="1">
	<digest>
		Toggle DSP off during offline rendering
	</digest>
	<description>
	Will disable DSP during video rendering process and restore to previous state upon render completion.
	<br/>
	The default is 1 (toggle DSP off)
	</description>
</attribute>
<attribute name="tf_support" get="1" set="1" type="bool" size="1">
	<digest>
		Support Transform Feedback using <o>jit.gl.tf</o>
	</digest>
	<description>
		Support a render process including Transform Feedback on a <o>jit.gl.mesh</o> using <o>jit.gl.tf</o>. Essentially, it deactivates the <at>fsaa</at> toggling prior to rendering, which otherwise requires a manual reactivation of the <o>jit.gl.tf</o>.
	<br/>
	The default is 0 (no <o>jit.gl.tf</o> support), the <at>fsaa</at> setting is by default on and would otherwise be overriden by <at>tf_support</at>.
	</description>
</attribute>
<attribute name="ae" get="1" set="1" type="bool" size="1">
	<digest>
		Play classic Adobe After Effects sounds after rendering
	</digest>
	<description>
		When set to 1 (default!), will play back the classic Adobe After Effects sound upon rendering completion. However, if DSP was disabled prior to rendering, this setting will not toggle the digital signal processing.
	</description>
</attribute>
	</attributelist>

		<!--MESSAGES-->

	<methodlist>
		<method name="record">
			<arglist />
			<digest>
				Start audio recording
			</digest>
			<description>
				Record all audio at the inlets of <o>the.jit.cochlea~</o>, <o>the.jit.amygdala~</o>, <o>the.mc.jit.amygdala~</o>, <o>the.cerebellum</o> or <o>the.mc.pac~</o> to respective storage formats
				<br/> Same as sending a <m>2</m> integer to first inlet.
			</description>
		</method>
		<method name="capture">
			<arglist />
			<digest>
				Start collecting matrices (deprecated)
			</digest>
			<description>
				Record all running matrices linked to the clock of the <o>jit.world</o> in use at the inlets of any <o>the.jit.retina</o>. If no <o>the.jit.retina</o> object is present in the current render context, this feature is disabled.
				<br/>
				Designed to capture the output of timed jitter objects like <o>jit.mo.join</o> which is linked to the <o>jit.world</o>. This feature is meanwhile deprecated and it is advised, to use <o>the.jit.mojo</o> for timely precise control of <o>jit.mo.func</o> objects instead.
			</description>
		</method>
		<method name="render">
			<arglist />
			<digest>
				Start frame-by-frame video rendering
			</digest>
			<description>
				Based on previously recorded <m>audio</m> and collected <m>data</m>, render video frame-by-frame through an attached jit.world. Everything recorded/collected is being reproduced at framerate at the respective outlets of <o>the.jit.cochlea~</o>, <o>the.mc.jit.cochlea~</o>, <o>the.jit.amygdala</o>, <o>the.mc.jit.amygdala</o>, <o>the.cerebellum</o> or <o>the.jit.retina</o> in expected formats.
				<br/><o>the.jit.mojo</o> will control any attached <o>jit.mo.func</o> object's timeline in this mode.
				<br/> Same as sending a <m>3</m> integer to first inlet.
			</description>
		</method>
		<method name="stop">
			<arglist />
			<digest>
				Stop any current render process
			</digest>
			<description>
				This will stop recording audio (without subsequent export) or rendering video. Any previously written video data will be compiled.
				<br/> Same as sending a <m>0</m> integer to first inlet.
			</description>
		</method>
		<method name="int">
			<arglist />
			<digest>
				Toggle operation modes
			</digest>
			<description>
				0 = halt any through output by children objects to support individual <m>frame</m> query. This mode is toggled automatically when a <m>frame</m> message with an integer specifying a frame is received.
				<br/>1 = stop any current process and enable <o>jit.world</o>, mostly identical to <m>0</m>
				<br/>2 = start recording audio and timed data, same as <m>record</m>
				<br/>3 = start rendering frame-by-frame, same as <m>render</m>
				<br/>(reserved) = start capturing timed matrices, same as <m>capture</m> but only supported with <o>the.jit.retina</o> present in the current render context
			</description>
		</method>
		<method name="open">
			<arglist />
			<digest>
				Open the GUI
			</digest>
			<description>
				All attributes can be set and operations performed in the GUI.
			</description>
		</method>
		<method name="settings">
			<arglist />
			<digest>
				Open the settings-GUI
			</digest>
			<description>
				Opens the specific window managing the render and recording settings, all of which can be hard-coded or sent as Max messages.
			</description>
		</method>
		<method name="close">
			<arglist />
			<digest>
				Hide the GUI
			</digest>
			<description>
				All attributes can be set and operations performed in the GUI.
			</description>
		</method>
		<method name="reveal">
			<arglist />
			<digest>
				Open the target directory
			</digest>
			<description>
				If a valid target directory is specified using the <at>dir</at> attribute, the message <m>reveal</m> will open the respective folder. This can be scheduled to happen at upon render completion using the <at>autoreveal</at> attribute.
			</description>
		</method>
		<method name="length">
			<arglist>
				<arg name="numeric length" optional="0" type="float" />
				<arg name="unit: ms, frames or samples" optional="0" type="symbol" />
			</arglist>
			<digest>
				Specify the length of the final video and all its subrecordings
			</digest>
			<description>
				The word <at>length</at> followed by a floating point or integer value and a symbol specifying a unit, will prepare recording of all children objects for the given length.
				<br/>
				<br />
				Supported units of time are
				<br/> <m>ms</m>
				<br/> <m>frames</m>
				<br/> <m>samples</m>
				<br/>
				<br/>
				Default: <m>length 1000. ms</m>, if the current framerate is set to <m>30.</m> (see also the <at>fps</at> listing), this would yield a length of <m>30 frames</m> and would equal the current <m>samplerate</m> (provided in samples per minute = 1000ms.)
				<br/>
				<br/>
				The word <m>length</m> without any arguments sets the recording mode to 'free' and will not stop until the <m>stop</m> message is received in the leftmost inlet or toggled in the GUI.
				<br/> Alternatively, the arguments <m>free</m> and <m>fixed</m> toggle between an assumed performance mode and a fixed time, provided by the respective arguments in a separate message.
				<br/> Note that a lot of data can ptoentially be accumulated in 'free' recording mode when stretched extensively. This pertains to analysed signals, as well as regular timing data and especially matrix-based anylsis. The latter, however, is currently happening in <o>the.mc.jit.amygdala~</o> where matrices are handled and written to disk in  temporary blocks to later populate a <o>jit.matrixset</o>.
			</description>
		</method>
		<method name="preview">
			<arglist>
				<arg name="position" optional="0" type="float" />
			</arglist>
			<digest>
				Normalised position (0. - 1.) (not yet supported)
			</digest>
			<description>
				Output the corresponding frame at the normalised position while not rendering by <o>jit.world</o> for all children objects.
				<br/>Note that any accumulative data cannot be reproduced correctly when previewing non-linearly.
				<br/>This method is not yet supported and may require fundamental recoding as well as documenting.
			</description>
		</method>
				<method name="frame">
			<arglist>
				<arg name="position" optional="0" type="int" />
			</arglist>
			<digest>
				Jump to specific frame
			</digest>
			<description>
				Output the corresponding frame at the specified position while not rendering by <o>jit.world</o> for all children objects.
				<br/>This will put <o>the.jit.thalamus</o> into playback mode '0', to re-enable output by children objects, send a '1' to the leftmost inlet (see the <m>int</m> listing).
				<br/>Note that any accumulative data cannot be reproduced correctly when previewing non-linearly. The state of any <m>jit_matrix</m> populated by <o>the.mc.jit.amygdala~</o> or <o>the.mc.jit.mnemonic~</o> will not be overwritten before recalling individual frames and will only be cleared prior to rendering when these objects' <at>autoclear</at> flag is set to '1'.
				<br/>This method has not yet been thoroughly tested and is sivbject to user feedback.
			</description>
		</method>
		<method name="solo">
			<arglist>
				<arg name="object-exportname" optional="0" type="symbol" />
				<arg name="solo-mode" optional="0" type="int" />
			</arglist>
	<digest>
		Toggle solo mode for children objects
	</digest>
	<description>
		According to the numeric argument, will toggle the recording/rendering behaviour of the object with the <m>exportname</m> provided as argument 1 in relation to other objects in the context
		<br/>
		<br/>0 = use current <at>active</at> flag if no other object is running <m>@solo 1</m> or <m>@solo 2</m>, otherwise will set the object to <m>active 0</m> (bypass)
		<br/>1 = toggle <at>active</at> operation mode to <m>1</m> (operate) along with other objects <m>@solo 1</m>, but not if any object is running <m>@solo 2</m>, in which case it will be muted
		<br/>2 = unique operation, operate only this object. This will set all other objects' <at>active</at> flag to <m>5</m> (mute)
		<br/>
		<br/>
		The message <m>solo 0</m> unsolos all objects and returns them to their set active flag
	</description>
</method>
		<method name="unsolo">
	<arglist />
	<digest>
		Remove all solo states in children objects
	</digest>
	<description>
		The message <m>unsolo</m> does not remove the <m>solo</m> state of the previous object alone but does so for all other objects in the context as well, each of which will assume their set <m>active</m> flag thereafter.
		<br/>
		Same as sending the message <m>solo 0</m>
	</description>
</method>
<method name="getstate">
<arglist />
<digest>
Query information about current objects in the context
</digest>
<description>
The message <m>getstate</m> will post relevant status information about every object in the current context to the Max Console and open the latter for viewing. Sending this message to individual objects will do so for the respective ones only. Send this message to monitor which objects will record or render and whether a meaningful name has been allocated to them.
</description>
</method>
		<method name="exportattrs">
			<arglist />
			<digest>
				Export all current settings to disk
			</digest>
			<description>
				Will write a JSON-file containing all current userdata to the directory specified by <at>dir</at>, or will prompt the user to choose a directory.
				<br/>
				These settings can be imported with <m>importattrs</m>
			</description>
		</method>
		<method name="importattrs">
			<arglist />
			<digest>
				Import previously saved render settings
			</digest>
			<description>
				Will attempt to read a JSON-file containing render settings from the directory specified by <at>dir</at>, or will prompt the user to choose a file.
				<br/>
				Current settings can be exported with <m>exportattrs</m>
			</description>
		</method>
	</methodlist>

	<!--SEEALSO (REMOVE FOR SIMPLICITY) -->
	<seealsolist>
		<seealso name="the.cochlea~"/>
		<seealso name="the.mc.jit.amygdala~"/>
		<seealso name="the.cerebellum"/>
		<seealso name="the.mc.pac~"/>
		<seealso name="the.jit.mojo"/>
		<seealso name="the.jit.pinealis"/>
		<seealso name="the.jit.tinnitus~"/>
		<seealso name="the.circadian"/>
		<seealso name="the.mc.jit.mnemonic~"/>
		<seealso module="Oneirotomy" name="oneirotomy_table_of_contents_topic" type="vignette" />
		<seealso module="Oneirotomy" name="oneirotomy-01_object-overview" type="vignette" />
	</seealsolist>

</c74object>
